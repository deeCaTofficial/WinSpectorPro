# src/winspector/core/modules/ai_analyzer.py
"""
–ú–æ–¥—É–ª—å –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å API Google Generative AI (Gemini).
–û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –ø—Ä–∏–Ω—è—Ç–∏–µ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –ø–ª–∞–Ω–æ–≤.
"""

import os
import json
import logging
import time
import hashlib
import re
import google.generativeai as genai
from typing import Dict, Any, List, Tuple

from .ai_base import AIBase
from .ai_communicator import AICommunicator # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è _extract_json

logger = logging.getLogger(__name__)

class ContentBlockedError(Exception):
    """–ò—Å–∫–ª—é—á–µ–Ω–∏–µ, –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º–æ–µ, –∫–æ–≥–¥–∞ –æ—Ç–≤–µ—Ç –æ—Ç API –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω."""
    def __init__(self, message, prompt_feedback):
        super().__init__(message)
        self.prompt_feedback = prompt_feedback

class _PlanValidator:
    """–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∫–ª–∞—Å—Å, –∏–Ω–∫–∞–ø—Å—É–ª–∏—Ä—É—é—â–∏–π –≤—Å—é –ª–æ–≥–∏–∫—É –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–ª–∞–Ω–∞ –æ—Ç –ò–ò."""
    def __init__(self, full_kb: Dict[str, Any], user_profiles: List[str]):
        self.user_profiles = user_profiles
        self.optimization_rules = {rule['id'].lower(): rule for rule in full_kb.get('optimization_rules', [])}
        self.cleanup_rules = {rule['category_id']: rule for rule in full_kb.get('cleanup_rules', [])}
        
        self.critical_items = {
            id for id, rule in self.optimization_rules.items() if rule.get('safety') == 'critical'
        }
        self.profile_relevant_items = {
            id for id, rule in self.optimization_rules.items()
            if any(p in rule.get('relevant_profiles', []) for p in self.user_profiles)
        }

    def validate(self, plan: Dict) -> Dict:
        """–ü—Ä–æ–≤–æ–¥–∏—Ç –ø–æ–ª–Ω—É—é, –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é –ø–ª–∞–Ω–∞."""
        if not isinstance(plan, dict) or "action_plan" not in plan or "cleanup_plan" not in plan:
            raise ValueError("–ü–ª–∞–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º —Å –∫–ª—é—á–∞–º–∏ 'action_plan' –∏ 'cleanup_plan'.")

        plan["action_plan"] = self._validate_action_plan(plan.get("action_plan", []))
        plan["cleanup_plan"] = self._validate_cleanup_plan(plan.get("cleanup_plan", {}))
        
        logger.info(f"–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–ª–∞–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û–¥–æ–±—Ä–µ–Ω–æ {len(plan['action_plan'])} –¥–µ–π—Å—Ç–≤–∏–π.")
        return plan

    def _validate_action_plan(self, action_plan: List[Dict]) -> List[Dict]:
        if not isinstance(action_plan, list):
            raise ValueError(f"'action_plan' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º, –∞ –Ω–µ {type(action_plan).__name__}.")

        safe_actions = []
        for action in action_plan:
            if not isinstance(action, dict) or not {"type", "id", "action"}.issubset(action.keys()):
                logger.warning(f"–ü—Ä–æ–ø—É—Å–∫ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è –≤ –ø–ª–∞–Ω–µ: {action}")
                continue

            item_id_lower = str(action["id"]).lower()
            
            # –£—Ä–æ–≤–µ–Ω—å 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å
            if item_id_lower in self.critical_items:
                logger.warning(f"–û–¢–ö–õ–û–ù–ï–ù–û –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∞–¥ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–º: {action['id']}")
                continue
            
            # –£—Ä–æ–≤–µ–Ω—å 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –ø—Ä–æ—Ñ–∏–ª—é
            # –ó–∞–ø—Ä–µ—â–∞–µ–º 'disable' –∏–ª–∏ 'remove' –¥–ª—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª—é —Å–ª—É–∂–±
            if action['action'] in ['disable', 'remove'] and item_id_lower in self.profile_relevant_items:
                logger.warning(f"–û–¢–ö–õ–û–ù–ï–ù–û –¥–µ–π—Å—Ç–≤–∏–µ '{action['action']}' –Ω–∞–¥ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–º '{action['id']}', "
                               f"—Ç–∞–∫ –∫–∞–∫ –æ–Ω –≤–∞–∂–µ–Ω –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–µ–π {self.user_profiles}.")
                continue
            
            safe_actions.append(action)
        return safe_actions

    # ### –£–õ–£–ß–®–ï–ù–ò–ï: –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–ª–∞–Ω–∞ –æ—á–∏—Å—Ç–∫–∏ ###
    def _validate_cleanup_plan(self, cleanup_plan: Dict) -> Dict:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –ø–ª–∞–Ω –æ—á–∏—Å—Ç–∫–∏ —Å —É—á–µ—Ç–æ–º –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        if not isinstance(cleanup_plan, dict):
            raise ValueError(f"'cleanup_plan' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º, –∞ –Ω–µ {type(cleanup_plan).__name__}.")
        
        safe_cleanup_plan = {}
        for category_id, decision in cleanup_plan.items():
            if not isinstance(decision, dict) or 'clean' not in decision:
                logger.warning(f"–ü—Ä–æ–ø—É—Å–∫ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∑–∞–ø–∏—Å–∏ –≤ cleanup_plan –¥–ª—è '{category_id}'")
                continue
            
            # –ï—Å–ª–∏ –ò–ò —Ä–µ—à–∏–ª –Ω–µ —á–∏—Å—Ç–∏—Ç—å, –º—ã —Å —ç—Ç–∏–º —Å–æ–≥–ª–∞—à–∞–µ–º—Å—è
            if not decision['clean']:
                safe_cleanup_plan[category_id] = decision
                continue

            rule = self.cleanup_rules.get(category_id)
            if not rule:
                logger.warning(f"–ò–ò –ø—Ä–µ–¥–ª–æ–∂–∏–ª –æ—á–∏—Å—Ç–∫—É –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category_id}'. –û—Ç–∫–ª–æ–Ω–µ–Ω–æ.")
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –¥–ª—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π
            is_sensitive_profile = any(p in ["Developer", "ContentCreator", "AudioEngineer"] for p in self.user_profiles)
            
            if rule.get('safety') == 'low' and is_sensitive_profile:
                logger.warning(f"–û–¢–ö–õ–û–ù–ï–ù–ê –æ—á–∏—Å—Ç–∫–∞ '{category_id}' —Å –Ω–∏–∑–∫–∏–º —É—Ä–æ–≤–Ω–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–ª—è –ø—Ä–æ—Ñ–∏–ª—è {self.user_profiles}.")
                safe_cleanup_plan[category_id] = {"clean": False}
            else:
                safe_cleanup_plan[category_id] = decision
                
        return safe_cleanup_plan


class AIAnalyzer(AIBase):
    """
    –û—Å–Ω–æ–≤–Ω–æ–π AI-–º–æ–¥—É–ª—å, –æ—Ç–≤–µ—á–∞—é—â–∏–π –∑–∞ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –ø–ª–∞–Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.
    """
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config, model_name='gemini-2.0-flash')

    def _ping_api(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API Gemini –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏."""
        try:
            timeout = self.config.get('ai_ping_timeout', 10)
            logger.debug(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API Gemini —Å —Ç–∞–π–º–∞—É—Ç–æ–º {timeout}—Å...")
            self.model.generate_content("ping", request_options={'timeout': timeout})
        except Exception as e:
            raise ConnectionError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ API Gemini: {e}") from e

    # ### –£–õ–£–ß–®–ï–ù–ò–ï: –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä generation_config ###
    async def _get_response_with_cache(self, prompt: str, context: str, use_cache: bool = True, generation_config: Dict[str, Any] = None) -> str:
        """–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–æ–¥ –¥–ª—è –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ –∏ –≥–∏–±–∫–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
        prompt_hash = hashlib.md5(prompt.encode('utf-8')).hexdigest()
        if use_cache and (cached_response := self.cache.get(prompt_hash)):
            response_text, timestamp = cached_response
            if time.time() - timestamp < self.config.get('ai_cache_ttl', 3600):
                logger.info(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è '{context}'.")
                return response_text

        logger.debug(f"–û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –≤ –ò–ò. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}")
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        gen_config = genai.types.GenerationConfig(**(generation_config or {}))
        
        response = await self.model.generate_content_async(prompt, generation_config=gen_config)
        
        if not response.parts:
            logger.warning(f"–û—Ç–≤–µ—Ç –æ—Ç –ò–ò –±—ã–ª –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω. –§–∏–¥–±–µ–∫: {response.prompt_feedback}")
            raise ContentBlockedError("–û—Ç–≤–µ—Ç –æ—Ç –ò–ò –±—ã–ª –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –∏–∑-–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.", prompt_feedback=response.prompt_feedback)

        response_text = response.text
        if use_cache:
            self.cache[prompt_hash] = (response_text, time.time())
        return response_text

    @staticmethod
    def _extract_json_from_response(text: str) -> Dict:
        """–ù–∞–¥–µ–∂–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç JSON –æ–±—ä–µ–∫—Ç –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –ò–ò, —É–¥–∞–ª—è—è –æ–±–µ—Ä—Ç–∫—É ```json."""
        # –ò—â–µ–º –±–ª–æ–∫ JSON, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–∫–ª—é—á–µ–Ω –≤ ```json ... ```
        match = re.search(r'```json\s*(\{.*\}|\[.*\])\s*```', text, re.DOTALL)
        
        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –±–ª–æ–∫ –≤ ```json, –∏–∑–≤–ª–µ–∫–∞–µ–º –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        if match:
            json_text = match.group(1)
        else:
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –≤–µ—Å—å —Ç–µ–∫—Å—Ç - —ç—Ç–æ JSON
            json_text = text

        try:
            return json.loads(json_text)
        except json.JSONDecodeError as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON. –û—à–∏–±–∫–∞: {e}. –¢–µ–∫—Å—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞: {json_text}")
            raise ValueError(f"JSON-–æ–±—ä–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ –ò–ò.") from e

    # --- –ú–µ—Ç–æ–¥—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ ---

    def _create_profile_prompt(self, system_data: Dict, kb_config: Dict) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        return f"""
        Analyze the user's system data to determine their primary profile from 'Gamer', 'Developer', 'Designer', 'OfficeWorker', 'HomeUser'.
        Base your decision on hardware specs, installed software keywords, and filesystem markers.
        Respond with ONLY ONE word in a JSON object: {{"profile": "..."}}.
        
        Profiler Configuration (keywords to look for):
        {json.dumps(kb_config, indent=2)}

        System Data:
        {json.dumps(system_data, indent=2, default=str)}
        """

    # ### –£–õ–£–ß–®–ï–ù–ò–ï: –ë–æ–ª–µ–µ —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏ —á–∏—Å—Ç—ã–π –ø—Ä–æ–º–ø—Ç ###
    def _create_plan_prompt(self, system_data: Dict, profiles: List[str], kb: Dict) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–ª–∞–Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏."""
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ, —á—Ç–æ–±—ã —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å –ò–ò –Ω–∞ –≥–ª–∞–≤–Ω–æ–º
        relevant_kb_rules = kb.get('optimization_rules', [])
        
        return f"""
        You are an expert Windows optimization engineer. Your task is to create a safe and effective optimization plan in a single, valid JSON object with two keys: "action_plan" and "cleanup_plan".

        **1. Analyze System Components (for "action_plan"):**
        - Review the `system_components` data.
        - Based on the user profiles {json.dumps(profiles)}, identify non-essential services and UWP apps.
        - Use the provided `KNOWLEDGE_BASE` to check for safety. NEVER suggest actions on items marked as 'critical'.
        - Do not suggest actions on items relevant to the user's profiles.
        - For each valid action, create an object for the "action_plan" list with keys: "type", "id", "action", "reason", "user_explanation_ru".

        **2. Analyze Junk Files (for "cleanup_plan"):**
        - Review the `junk_files_report`. Each key is a category to be cleaned.
        - For EVERY category, create an entry in the "cleanup_plan" dictionary.
        - Set the value to `{{"clean": true}}` if you are confident it is safe to clean for this user.
        - Set it to `{{"clean": false}}` if it's risky (e.g., cleaning `python_pip_cache` for a 'Developer').

        **USER PROFILES:** {json.dumps(profiles)}

        **KNOWLEDGE BASE (Safety Rules):**
        {json.dumps(relevant_kb_rules, indent=2)}

        **SYSTEM SNAPSHOT (Data to Analyze):**
        {json.dumps(system_data, indent=2, default=str)}

        Respond with ONLY the JSON object.
        """

    def _create_report_prompt(self, summary: Dict, plan: List[Dict]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞."""
        def format_bytes(b):
            gb, mb, kb = b / (1024**3), b / (1024**2), b / 1024
            if gb >= 1: return f"{gb:.2f} –ì–ë"
            if mb >= 1: return f"{mb:.1f} –ú–ë"
            if kb >= 1: return f"{kb:.1f} –ö–ë"
            return f"{b} –±–∞–π—Ç" if b > 0 else "0 –±–∞–π—Ç"
        
        cleaned_size = format_bytes(summary.get("cleanup", {}).get("cleaned_size_bytes", 0))
        debloat_summary = summary.get("debloat", {})
        actions_performed_str = "\n".join([f"‚úÖ {action['user_explanation_ru']}" for action in plan if action.get("user_explanation_ru")])

        return f"""
        You are "WinSpector AI Communicator". Your job is to create a friendly, encouraging report in Russian Markdown.
        
        CONTEXT:
        The user has just completed a system optimization. The tone should be positive and celebratory. Use simple, clear language.
        
        METRICS:
        - Space freed: {cleaned_size}
        - Services disabled: {len(debloat_summary.get("disabled_services", []))}
        - UWP apps removed: {len(debloat_summary.get("removed_apps", []))}
        
        ACTIONS PERFORMED:
        {actions_performed_str}
        
        TASK:
        Create a concise, well-formatted report in Russian Markdown with an encouraging headline, a summary of key metrics, a list of actions, and a reassuring closing statement. Use emojis (‚úÖ, üöÄ, üí™).
        """

    def _create_suggestions_prompt(self, **kwargs) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é."""
        # –≠—Ç–æ—Ç –ø—Ä–æ–º–ø—Ç –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π, –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ –æ–Ω —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –∑–¥–µ—Å—å
        return f"""
        You are "WinSpector AI Architect", a lead developer reviewing an optimization session.
        Your goal is to suggest future improvements.
        
        SESSION ANALYSIS:
        {json.dumps(kwargs, indent=2, ensure_ascii=False)}
        
        TASK:
        Based on this session's data, suggest 3-5 concrete improvements for future versions.
        Respond in Russian Markdown.
        """

    # --- –ü—É–±–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã API ---

    async def determine_user_profile(self, system_data: Dict, kb_config: Dict) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        prompt = self._create_profile_prompt(system_data, kb_config)
        response_text = await self._get_response_with_cache(prompt, "determine_user_profile")
        try:
            profile_data = self._extract_json_from_response(response_text)
            profile = profile_data.get("profile", "HomeUser").strip()
            logger.info(f"–ò–ò –æ–ø—Ä–µ–¥–µ–ª–∏–ª –ø—Ä–æ—Ñ–∏–ª—å –∫–∞–∫: {profile}")
            return profile
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
            return "HomeUser"

    async def generate_distillation_plan(self, system_data: Dict, profiles: List[str], kb: Dict) -> Dict:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –ø–ª–∞–Ω –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞."""
        prompt = self._create_plan_prompt(system_data, profiles, kb)
        
        # ### –£–õ–£–ß–®–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–æ–≥—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è JSON ###
        generation_config = {
            "temperature": 0.1,
            "max_output_tokens": 8192,
        }
        
        try:
            response_text = await self._get_response_with_cache(
                prompt, "generate_distillation_plan", 
                use_cache=False, 
                generation_config=generation_config
            )
            plan = AICommunicator._extract_json_from_response(response_text)
            
            validator = _PlanValidator(full_kb=kb, user_profiles=profiles)
            safe_plan = validator.validate(plan)
            
            logger.debug("–ü–æ–ª—É—á–µ–Ω –∏ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–ª–∞–Ω –æ—Ç –ò–ò.")
            return safe_plan
        except ValueError as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∏–ª–∏ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –ø–ª–∞–Ω –æ—Ç –ò–ò: {e}", exc_info=True)
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø–ª–∞–Ω –æ—Ç –ò–ò. –û—Ç–≤–µ—Ç –±—ã–ª –ø–æ–≤—Ä–µ–∂–¥–µ–Ω –∏–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–µ–Ω.") from e
        except ContentBlockedError as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–ª–∞–Ω: {e}", exc_info=True)
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–ª–∞–Ω: –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò –±—ã–ª –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω.") from e

    def _validate_plan(self, plan: Dict, kb: Dict) -> Dict:
        """
        –ü—Ä–æ–≤–æ–¥–∏—Ç —Å—Ç—Ä–æ–≥—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é –ø–ª–∞–Ω–∞ –æ—Ç –ò–ò.
        –ù–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è —É–¥–∞–ª—è—é—Ç—Å—è –∏–∑ –ø–ª–∞–Ω–∞, –∞ –Ω–µ –≤—ã–∑—ã–≤–∞—é—Ç –æ—à–∏–±–∫—É.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—á–∏—â–µ–Ω–Ω—ã–π, –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–ª–∞–Ω.
        """
        if not isinstance(plan, dict) or "action_plan" not in plan or "cleanup_plan" not in plan:
            raise ValueError("–ü–ª–∞–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º —Å –∫–ª—é—á–∞–º–∏ 'action_plan' –∏ 'cleanup_plan'.")

        action_plan = plan.get("action_plan", [])
        if not isinstance(action_plan, list):
            raise ValueError(f"'action_plan' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º, –∞ –Ω–µ {type(action_plan).__name__}.")

        critical_services = {s.lower() for s in kb.get("absolutely_critical", {}).get("services", [])}
        critical_uwp_apps = {a.lower() for a in kb.get("absolutely_critical", {}).get("uwp_apps", [])}

        safe_actions = []
        for action in action_plan:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            if not isinstance(action, dict) or not {"type", "id", "action"}.issubset(action.keys()):
                logger.warning(f"–ü—Ä–æ–ø—É—Å–∫ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è –≤ –ø–ª–∞–Ω–µ: {action}")
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å
            item_id_lower = str(action["id"]).lower()
            is_unsafe = False
            if action["type"] == "service" and item_id_lower in critical_services:
                logger.warning(f"–û–¢–ö–õ–û–ù–ï–ù–û –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∞–¥ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π —Å–ª—É–∂–±–æ–π: {action['id']}")
                is_unsafe = True
            if action["type"] == "uwp_app" and item_id_lower in critical_uwp_apps:
                logger.warning(f"–û–¢–ö–õ–û–ù–ï–ù–û –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∞–¥ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º UWP-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º: {action['id']}")
                is_unsafe = True
            
            if not is_unsafe:
                safe_actions.append(action)

        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–ª–∞–Ω —Ç–æ–ª—å–∫–æ –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ –¥–µ–π—Å—Ç–≤–∏—è–º–∏
        plan["action_plan"] = safe_actions
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è cleanup_plan –æ—Å—Ç–∞–µ—Ç—Å—è
        cleanup_plan = plan.get("cleanup_plan", {})
        if not isinstance(cleanup_plan, dict):
            raise ValueError(f"'cleanup_plan' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º, –∞ –Ω–µ {type(cleanup_plan).__name__}.")

        logger.info(f"–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–ª–∞–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û–¥–æ–±—Ä–µ–Ω–æ {len(safe_actions)} –¥–µ–π—Å—Ç–≤–∏–π.")
        return plan

    async def generate_final_report(self, summary: Dict, plan: List[Dict]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞.")
        prompt = self._create_report_prompt(summary, plan)
        return await self._get_response_with_cache(prompt, "generate_final_report", use_cache=False)

    async def get_ai_suggestions_for_improvement(self, **kwargs) -> str:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–µ—Å—Å–∏—é –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤."""
        logger.info("–ó–∞–ø—Ä–æ—Å –∫ –ò–ò –Ω–∞ —Å–∞–º–æ—Ä–µ—Ñ–ª–µ–∫—Å–∏—é –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é.")
        prompt = self._create_suggestions_prompt(**kwargs)
        # –≠—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å –≤—Å–µ–≥–¥–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–≤–µ–∂–∏–º, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à
        response = await self.model.generate_content_async(prompt)
        return response.text