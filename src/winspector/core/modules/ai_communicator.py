# src/winspector/core/modules/ai_communicator.py
"""
–ú–æ–¥—É–ª—å, –æ—Ç–≤–µ—á–∞—é—â–∏–π –∑–∞ "–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ" –∑–∞–¥–∞—á–∏ –ò–ò:
- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤.
"""
import json
import logging
import re
from typing import Dict, Any, List

# –ù–∞—Å–ª–µ–¥—É–µ–º—Å—è –æ—Ç –±–∞–∑–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞ —Å –æ–±—â–µ–π –ª–æ–≥–∏–∫–æ–π
from .ai_base import AIBase

logger = logging.getLogger(__name__)


class AICommunicator(AIBase):
    """
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ò–ò –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–º.
    –û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –∑–∞–¥–∞—á–∏, –Ω–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.
    """
    def __init__(self, config: Dict[str, Any]):
        # –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥—É—é, –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–π, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        super().__init__(config, model_name='gemini-2.0-flash')

    @staticmethod
    def _extract_json_from_response(text: str) -> Dict:
        """–ù–∞–¥–µ–∂–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç JSON –æ–±—ä–µ–∫—Ç –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –ò–ò, —É–¥–∞–ª—è—è –æ–±–µ—Ä—Ç–∫—É ```json."""
        # –ò—â–µ–º –±–ª–æ–∫ JSON, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–∫–ª—é—á–µ–Ω –≤ ```json ... ```
        match = re.search(r'```json\s*(\{.*\}|\[.*\])\s*```', text, re.DOTALL)
        
        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –±–ª–æ–∫ –≤ ```json, –∏–∑–≤–ª–µ–∫–∞–µ–º –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        if match:
            json_text = match.group(1)
        else:
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –≤–µ—Å—å —Ç–µ–∫—Å—Ç - —ç—Ç–æ JSON
            json_text = text

        try:
            return json.loads(json_text)
        except json.JSONDecodeError as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON. –û—à–∏–±–∫–∞: {e}. –¢–µ–∫—Å—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞: {json_text}")
            raise ValueError(f"JSON-–æ–±—ä–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ –ò–ò.") from e

    # --- –ú–µ—Ç–æ–¥—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ ---

    def _create_profile_prompt(self, system_data: Dict, kb_config: Dict) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        return f"""
        Analyze the user's system data to determine their primary profile.
        Available profiles: 'Gamer', 'Developer', 'Designer', 'OfficeWorker', 'HomeUser'.
        Base your decision on hardware specs, installed software keywords, and filesystem markers.
        Respond with ONLY ONE word in a JSON object: {{"profile": "..."}}.
        
        Profiler Configuration (keywords to look for):
        {json.dumps(kb_config, indent=2)}

        System Data:
        {json.dumps(system_data, indent=2, default=str)}
        """

    def _create_report_prompt(self, summary: Dict, plan: List[Dict]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞."""
        def format_bytes(b: int) -> str:
            if b <= 0: return "0 –±–∞–π—Ç"
            gb = b / (1024**3)
            if gb >= 1: return f"{gb:.2f} –ì–ë"
            mb = b / (1024**2)
            if mb >= 1: return f"{mb:.1f} –ú–ë"
            kb = b / 1024
            if kb >= 1: return f"{kb:.1f} –ö–ë"
            return f"{b} –±–∞–π—Ç"
            
        debloat_summary = summary.get("debloat", {})
        cleanup_summary = summary.get("cleanup", {})
        
        cleaned_size = format_bytes(cleanup_summary.get("cleaned_size_bytes", 0))
        disabled_services = len(debloat_summary.get("disabled_services", []))
        removed_apps = len(debloat_summary.get("removed_apps", []))
        
        actions_performed_str = "\n".join(
            [f"‚úÖ {action['user_explanation_ru']}" for action in plan if action.get("user_explanation_ru")]
        )
        if not actions_performed_str:
            actions_performed_str = "–î–µ–π—Å—Ç–≤–∏–π –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–µ –ø–æ—Ç—Ä–µ–±–æ–≤–∞–ª–æ—Å—å."

        return f"""
        You are "WinSpector AI Communicator". Your job is to create a friendly, encouraging report in Russian Markdown.
        The tone should be positive and celebratory. Use simple, clear language and emojis (‚úÖ, üöÄ, üí™).
        
        METRICS:
        - Space freed: {cleaned_size}
        - Services disabled: {disabled_services}
        - UWP apps removed: {removed_apps}
        
        ACTIONS PERFORMED:
        {actions_performed_str}
        
        TASK:
        Create a concise, well-formatted report in Russian Markdown. It must include:
        1. An encouraging headline.
        2. A summary of key metrics.
        3. A "–ß—Ç–æ –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ:" section with the list of actions.
        4. A reassuring closing statement about safety.
        """

    # --- –ü—É–±–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã API ---

    async def determine_user_profile(self, system_data: Dict, kb_config: Dict) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
        logger.info("–ó–∞–ø—Ä–æ—Å –∫ –ò–ò –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
        prompt = self._create_profile_prompt(system_data, kb_config)
        response_text = await self._get_response_with_cache(prompt, "determine_user_profile")
        
        try:
            profile_data = self._extract_json_from_response(response_text)
            profile = profile_data.get("profile", "HomeUser").strip().replace('"', '')
            if not profile: return "HomeUser" # –ï—Å–ª–∏ –ø—Ä–æ—Ñ–∏–ª—å –ø—É—Å—Ç–æ–π
            logger.info(f"–ò–ò –æ–ø—Ä–µ–¥–µ–ª–∏–ª –ø—Ä–æ—Ñ–∏–ª—å –∫–∞–∫: {profile}")
            return profile
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –æ—Ç–≤–µ—Ç–∞ –ò–ò: {e}")
            return "HomeUser"  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

    async def generate_final_report(self, summary: Dict, plan: List[Dict]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –æ—Ç—á–µ—Ç –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown."""
        logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞.")
        prompt = self._create_report_prompt(summary, plan)
        # –û—Ç—á–µ—Ç –≤—Å–µ–≥–¥–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–≤–µ–∂–∏–º, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à
        return await self._get_response_with_cache(prompt, "generate_final_report", use_cache=False)

    async def get_ai_suggestions_for_improvement(self, **kwargs) -> str:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–µ—Å—Å–∏—é –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤."""
        # –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –º–æ–∂–µ—Ç –æ—Å—Ç–∞–≤–∞—Ç—å—Å—è —Ç–∞–∫–∏–º –∂–µ, —Ç–∞–∫ –∫–∞–∫ –µ–≥–æ –ø—Ä–æ–º–ø—Ç –æ—á–µ–Ω—å —Å–ø–µ—Ü–∏—Ñ–∏—á–µ–Ω
        # –∏ —Å–ª–æ–∂–µ–Ω –¥–ª—è —Ñ–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –º–µ—Ç–æ–¥–µ.
        logger.info("–ó–∞–ø—Ä–æ—Å –∫ –ò–ò –Ω–∞ —Å–∞–º–æ—Ä–µ—Ñ–ª–µ–∫—Å–∏—é –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é.")
        
        prompt = f"""
        You are "WinSpector AI Architect", a lead developer reviewing an optimization session.
        Your goal is to suggest future improvements for the application.
        
        SESSION ANALYSIS (JSON format):
        {json.dumps(kwargs, indent=2, ensure_ascii=False, default=str)}
        
        TASK:
        Based on this session's data, suggest 3-5 concrete, technical improvements for future versions.
        Focus on proactive monitoring, security, and commercial readiness.
        Respond in Russian Markdown.
        """
        # –≠—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å —Ç–æ–∂–µ –≤—Å–µ–≥–¥–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–≤–µ–∂–∏–º
        response = await self.model.generate_content_async(prompt)
        return response.text